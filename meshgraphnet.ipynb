{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOJhdO3OuQCGCpsw5vF4qwJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yawmid/3rd-Year-Project/blob/main/meshgraphnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Accessing data from google drive**\n",
        "\n",
        "Organising my data in Google Drive was convenient for me"
      ],
      "metadata": {
        "id": "so88Xk11DgTX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "o6wBr2qtttgH",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Installing and importing relevant libraries**"
      ],
      "metadata": {
        "id": "6jKdTneIDpmJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install trimesh torch-geometric"
      ],
      "metadata": {
        "id": "bcT34jIPu5gX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Some of the libraries only work with an older version of pytorch, specifically torch-scatter and torch-sparse. They haven't been updated yet to torch 2.9.0. The following code uninstalls torch 2.9.0 and reinstalls torch 2.8.0. First check which PyTorch and CUDA version is installed. Verify that it is supported using this link https://data.pyg.org/whl/*\n",
        "\n",
        "*If it is, you don't need to bother with changing the PyTorch version*"
      ],
      "metadata": {
        "id": "H9FY5m6Vs4J5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import sys\n",
        "\n",
        "print(f\"PyTorch Version: {torch.__version__}\")\n",
        "print(f\"CUDA Version: {torch.version.cuda}\")\n",
        "print(f\"Python Version: {sys.version.split()[0]}\")"
      ],
      "metadata": {
        "id": "opSa0gBKt3xE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*If not run the code below and change the install link accordingly*"
      ],
      "metadata": {
        "id": "VX6hnrmmukdL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#pip uninstall torch torchvision torchaudio -y"
      ],
      "metadata": {
        "id": "YH77SOJSsD-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install torch==2.8.0 torchvision==0.23.0 torchaudio==2.8.0"
      ],
      "metadata": {
        "id": "EFls6YRKsH_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-2.8.0+cu128.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-2.8.0+cu128.html\n",
        "!pip install torch-geometric\n",
        "!pip install -q git+https://github.com/snap-stanford/deepsnap.git"
      ],
      "metadata": {
        "collapsed": true,
        "id": "bZCZJtoAi5Jf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import trimesh\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from scipy.spatial import cKDTree\n",
        "from tqdm import trange\n",
        "import random\n",
        "import glob\n",
        "from tqdm import tqdm\n",
        "import os.path as osp\n",
        "\n",
        "import torch.nn as nn\n",
        "from torch.nn import Linear, Sequential, LayerNorm, ReLU\n",
        "from torch_geometric.nn.conv import MessagePassing\n",
        "from torch_geometric.data import DataLoader\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.data import Dataset\n",
        "import torch_scatter"
      ],
      "metadata": {
        "id": "ujNpzP5Buyv_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Preparing and loading datasets**"
      ],
      "metadata": {
        "id": "5rxRMyfgBMx_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/content/drive/MyDrive/3rd_year_project/Training'\n",
        "\n",
        "root_dir = os.getcwd()\n",
        "dataset_dir = os.path.join(root_dir, 'Graphs/dataset.pt')\n",
        "checkpoint_dir = os.path.join(root_dir, 'checkpoints')\n",
        "postprocess_dir = os.path.join(root_dir, 'animations')\n",
        "\n",
        "print(dataset_dir)"
      ],
      "metadata": {
        "id": "dvAxDIR1BTQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Building graphs**\n",
        "\n",
        "\n",
        "This code loads the STL and WSS data. It first loads the STL using trimesh.load, we then have to merge the vertices, this prevents a vertex being counted more than once, the number of vertices should be equal to the number of nodes we get from the ansys data.\n",
        "\n",
        "**Geom**  is the actual geometrical data for the artery, it has dimensions [num_nodes,3], (x,y,z) coordinates for each node.\n",
        "\n",
        "**Edge index** describes how our nodes are connected to each other, they are the edges of our graph\n",
        "\n",
        "**Edge Attributes**, this includes the relative distance (x), relative distance (y), relative distance (z) and the total length. It's important that we encode these distances between nodes, the physics of a fluid particle between adjacent nodes depends on the distance and the direction between them, without this the model may struggle to learn the physics of the system.\n",
        "\n",
        "There is also an alignment procedure coded in. When the WSS data was exported from Ansys, it was ordered by node number, but there was no guarantee that it aligned with the nodes from the STL (it turns out it did line up fairly perfectly but this was not known at the time). tree = cKDtree(target_pos) creates a spatial map in a tree structure, it then takes every vertex in the STL map and matches it to the closest node (spatially) in the CSV. After running, it turns out the max distance between the nodes was zero, the data was already aligned to the STL.\n",
        "\n",
        "For each node we also have input features. The node type has to be defined as specified by the original research paper https://arxiv.org/abs/2010.03409. The other node features chosen at the moment include, input flow and Reynold's number.\n",
        "\n",
        "A lot of this code is based on the work of Isaac Ju, Robert Lupoiu, and Rayan Kanfar, as part of the Stanford CS224W course project.\n",
        "\n",
        "The link to their medium post is provided here: https://medium.com/stanford-cs224w/learning-mesh-based-flow-simulations-on-graph-networks-44983679cf2d.\n",
        "\n",
        "The link to their Colab notebook is provided here: https://colab.research.google.com/drive/1mZAWP6k9R0DE5NxPzF8yL2HpIUG3aoDC?usp=sharing#scrollTo=n33F2kSeJlQ3\n",
        "\n",
        "Gemini 3 pro was used to debug and was extremely useful when I hit a wall a couple of times.\n",
        "\n"
      ],
      "metadata": {
        "id": "tNYDGl2kD4WO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z7BYU2_ptnI8"
      },
      "outputs": [],
      "source": [
        "def process_single_sample(stl_path, wss_path, flow_input):\n",
        "\n",
        "    # --- 1. Load Geometry (STL) ---\n",
        "    mesh = trimesh.load(stl_path, force = 'mesh')\n",
        "    mesh.merge_vertices()\n",
        "\n",
        "    geom = torch.tensor(mesh.vertices, dtype=torch.float)\n",
        "    num_nodes = geom.shape[0]\n",
        "\n",
        "    # Build Edges\n",
        "    faces = mesh.faces\n",
        "    edges = []\n",
        "    for face in faces:\n",
        "        edges.append([face[0], face[1]])\n",
        "        edges.append([face[1], face[2]])\n",
        "        edges.append([face[2], face[0]])\n",
        "        # Bidirectional\n",
        "        edges.append([face[1], face[0]])\n",
        "        edges.append([face[2], face[1]])\n",
        "        edges.append([face[0], face[2]])\n",
        "\n",
        "    edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
        "    edge_index = torch.unique(edge_index, dim=1)\n",
        "\n",
        "\n",
        "    # --- 3. CALCULATE EDGE ATTRIBUTES\n",
        "    # compute relative position (u_ij) and distance (norm)\n",
        "    # row = source nodes, col = target nodes\n",
        "    row, col = edge_index\n",
        "\n",
        "    u_i = geom[row]\n",
        "    u_j = geom[col]\n",
        "\n",
        "    # Relative position vector (Direction)\n",
        "    u_ij = u_i - u_j\n",
        "\n",
        "    # Euclidean distance (Magnitude)\n",
        "    u_ij_norm = torch.norm(u_ij, p=2, dim=1, keepdim=True)\n",
        "\n",
        "    # Edge Attributes: [dx, dy, dz, distance]\n",
        "    edge_attr = torch.cat((u_ij, u_ij_norm), dim=-1).type(torch.float)\n",
        "\n",
        "    #2. Process Features (Flow Input + Node Type) ---\n",
        "    flow_tensor = torch.tensor(flow_input, dtype=torch.float).unsqueeze(0).repeat(num_nodes, 1)\n",
        "\n",
        "    node_type = torch.zeros((num_nodes, 1), dtype=torch.float) # 0 for Wall\n",
        "\n",
        "    x = torch.cat([flow_tensor, node_type], dim=1)\n",
        "\n",
        "    # 3. Load WSS\n",
        "    df = pd.read_csv(wss_path, skiprows=5)\n",
        "    df.columns = [c.strip() for c in df.columns]\n",
        "    target_pos = df[['X [ m ]', 'Y [ m ]', 'Z [ m ]']].values\n",
        "    wss_data = df['Wall Shear Z [ Pa ]'].values\n",
        "\n",
        "    # === ALIGNMENT BLOCK ===\n",
        "    # We find which row in the CSV corresponds to each vertex in our mesh\n",
        "    tree = cKDTree(target_pos)\n",
        "    distances, indices = tree.query(mesh.vertices)\n",
        "\n",
        "\n",
        "    # Ensure the matching is accurate, if this warning comes up, check over your data\n",
        "    if np.max(distances) > 1e-4:\n",
        "        print(f\"Warning: High alignment error ({np.max(distances)}). Check units (m vs mm).\")\n",
        "\n",
        "    # Reorder the WSS data to match the mesh\n",
        "    wss_aligned = wss_data[indices]\n",
        "\n",
        "    # =======================\n",
        "    y = torch.tensor(wss_aligned, dtype=torch.float)\n",
        "    if y.ndim == 1:\n",
        "        y = y.unsqueeze(1)\n",
        "\n",
        "    # --- 4. Build data object\n",
        "    data = Data(features=x, edge_index=edge_index,edge_attr= edge_attr, y=y, pos=geom)\n",
        "\n",
        "    return data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*One instance to make sure the graph building works*"
      ],
      "metadata": {
        "id": "L8cxCPWrL8s3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stl_path = '/content/drive/MyDrive/3rd_year_project/Training/STLs/CFD batch00001_wall.stl'\n",
        "wss_path = '/content/drive/MyDrive/3rd_year_project/Training/WSS/CFD batch00001_wss.csv'\n",
        "\n",
        "\n",
        "data = process_single_sample(stl_path, wss_path, flow_input=[1,0])\n",
        "print(data)"
      ],
      "metadata": {
        "id": "elMJhodft2W5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import torch\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "# Ensure you have your imports: trimesh, numpy, etc.\n",
        "\n",
        "def create_dataset_individual_files(stl_dir, wss_dir, flow_input, output_dir):\n",
        "    \"\"\"\n",
        "    Processes STLs and saves them as individual .pt files in output_dir.\n",
        "    \"\"\"\n",
        "\n",
        "    # --- 1. Setup Output Directory ---\n",
        "    if not os.path.exists(output_dir):\n",
        "        print(f\"Creating output directory: {output_dir}\")\n",
        "        os.makedirs(output_dir)\n",
        "    else:\n",
        "        print(f\"Output directory exists: {output_dir}\")\n",
        "\n",
        "    # --- 2. Load Flow Rates Table ---\n",
        "    print(f\"Loading flow rates from {flow_input}...\")\n",
        "    flow_df = pd.read_csv(flow_input)\n",
        "    flow_map = dict(zip(flow_df['Filename'], flow_df['FlowRate_kg_s']))\n",
        "\n",
        "    # --- 3. Find all STL files ---\n",
        "    stl_files = sorted(glob.glob(os.path.join(stl_dir, \"*.stl\")))\n",
        "    print(f\"Found {len(stl_files)} STL files. Starting batch processing...\")\n",
        "\n",
        "    success_count = 0\n",
        "\n",
        "    for stl_path in tqdm(stl_files):\n",
        "        try:\n",
        "            # A. Extract ID\n",
        "            filename = os.path.basename(stl_path)\n",
        "            file_id = os.path.splitext(filename)[0]\n",
        "            file_id = file_id.replace(\"_wall\", \"\")\n",
        "\n",
        "            # B. Define Save Path\n",
        "            # We save it as \"Case123.pt\"\n",
        "            save_path = os.path.join(output_dir, f\"{file_id}.pt\")\n",
        "\n",
        "            # C. Check if already done (Resume capability)\n",
        "            if os.path.exists(save_path):\n",
        "                # print(f\"Skipping {file_id} (already exists).\")\n",
        "                continue\n",
        "\n",
        "            # D. Find Flow Rate\n",
        "            if file_id not in flow_map:\n",
        "                print(f\"Skipping {file_id}: ID not found in flow_rates.csv\")\n",
        "                continue\n",
        "            flow_val = flow_map[file_id]\n",
        "\n",
        "            # E. Find WSS file\n",
        "            wss_filename = f\"{file_id}_wss.csv\"\n",
        "            wss_path = os.path.join(wss_dir, wss_filename)\n",
        "\n",
        "            if not os.path.exists(wss_path):\n",
        "                print(f\"Skipping {file_id}: WSS file not found\")\n",
        "                continue\n",
        "\n",
        "            # F. Process Graph (Using your existing function)\n",
        "            graph = process_single_sample(stl_path, wss_path, [flow_val])\n",
        "\n",
        "            # --- G. SAVE INSTANTLY ---\n",
        "            torch.save(graph, save_path)\n",
        "            success_count += 1\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"FAILED to process {filename}: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "    print(f\"Processing complete. Saved {success_count} new graphs to {output_dir}\")"
      ],
      "metadata": {
        "id": "7lPispipBc09"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stl_path = '/content/drive/MyDrive/3rd_year_project/Training/STLs'\n",
        "wss_path = '/content/drive/MyDrive/3rd_year_project/Training/WSS'\n",
        "flow_rates = '/content/drive/MyDrive/3rd_year_project/Training/flow_rates.csv'\n",
        "output_dir = '/content/drive/MyDrive/3rd_year_project/Training/Graphs'\n",
        "\n",
        "create_dataset_individual_files(stl_path, wss_path, flow_rates, output_dir)"
      ],
      "metadata": {
        "id": "R0kv_Sf6DXyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GraphFolderDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None, pre_transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        # Get list of all .pt files in the directory\n",
        "        self.file_list = sorted(glob.glob(os.path.join(root_dir, '*.pt')))\n",
        "        super(GraphFolderDataset, self).__init__(root_dir, transform, pre_transform)\n",
        "\n",
        "    def len(self):\n",
        "        return len(self.file_list)\n",
        "\n",
        "    def get(self, idx):\n",
        "        # Load the specific file corresponding to idx\n",
        "        data = torch.load(self.file_list[idx],weights_only=False)\n",
        "        return data"
      ],
      "metadata": {
        "id": "CVuQic25PvgG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Normalising**\n",
        "\n",
        "Normalising is common practice is machine learning. The input features and output parameters are scaled to a uniform range, this prevents features with a large numerical range from dominating the learning process, it stablises training\n"
      ],
      "metadata": {
        "id": "v-wqwOzNKofr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize(to_normalize, mean_vec, std_vec):\n",
        "    return (to_normalize - mean_vec) / std_vec\n",
        "\n",
        "def unnormalize(to_unnormalize, mean_vec, std_vec):\n",
        "    return to_unnormalize * std_vec + mean_vec\n",
        "\n",
        "def get_stats(data_list):\n",
        "\n",
        "    #mean and std of the node features are calculated\n",
        "    mean_vec_x = torch.zeros(data_list[0].x.shape[1:])\n",
        "    std_vec_x = torch.zeros(data_list[0].x.shape[1:])\n",
        "\n",
        "    #mean and std of the edge features are calculated\n",
        "    mean_vec_edge = torch.zeros(data_list[0].edge_attr.shape[1:])\n",
        "    std_vec_edge = torch.zeros(data_list[0].edge_attr.shape[1:])\n",
        "\n",
        "    mean_vec_y = torch.zeros(data_list[0].y.shape[1:])\n",
        "    std_vec_y = torch.zeros(data_list[0].y.shape[1:])\n",
        "\n",
        "    # This prevents your computer from breaking or more accurately\n",
        "    #Define the maximum number of accumulations to perform such that we do\n",
        "    #not encounter memory issues\n",
        "\n",
        "    max_accumulations = 10**8\n",
        "\n",
        "    #Define a very small value for normalising to\n",
        "    eps = torch.tensor(1e-8)\n",
        "\n",
        "    num_accs_x = 0\n",
        "    num_accs_edge = 0\n",
        "    num_accs_y = 0\n",
        "\n",
        "    for dp in data_list:\n",
        "        # Accumulate sums and squared sums\n",
        "        mean_vec_x += torch.sum(dp.x, dim=0)\n",
        "        std_vec_x += torch.sum(dp.x**2, dim=0)\n",
        "        num_accs_x += dp.x.shape[0]\n",
        "\n",
        "        mean_vec_edge += torch.sum(dp.edge_attr, dim=0)\n",
        "        std_vec_edge += torch.sum(dp.edge_attr**2, dim=0)\n",
        "        num_accs_edge += dp.edge_attr.shape[0]\n",
        "\n",
        "        mean_vec_y += torch.sum(dp.y, dim=0)\n",
        "        std_vec_y += torch.sum(dp.y**2, dim=0)\n",
        "        num_accs_y += dp.y.shape[0]\n",
        "\n",
        "        if(num_accs_x>max_accumulations or num_accs_edge>max_accumulations or num_accs_y>max_accumulations):\n",
        "            break\n",
        "\n",
        "    # Calculate Mean & Std\n",
        "    mean_vec_x = mean_vec_x / num_accs_x\n",
        "    std_vec_x = torch.maximum(torch.sqrt(std_vec_x / num_accs_x - mean_vec_x**2), eps)\n",
        "\n",
        "    mean_vec_edge = mean_vec_edge / num_accs_edge\n",
        "    std_vec_edge = torch.maximum(torch.sqrt(std_vec_edge / num_accs_edge - mean_vec_edge**2), eps)\n",
        "\n",
        "    mean_vec_y = mean_vec_y / num_accs_y\n",
        "    std_vec_y = torch.maximum(torch.sqrt(std_vec_y / num_accs_y - mean_vec_y**2), eps)\n",
        "\n",
        "    return [mean_vec_x, std_vec_x, mean_vec_edge, std_vec_edge, mean_vec_y, std_vec_y]\n"
      ],
      "metadata": {
        "id": "5dHaNVsg1w0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Encoder**\n",
        "\n",
        "MeshGraphNets have three main components in its architecture: encoder, processor and decoder\n",
        "\n",
        "The encoder takes the the input data and resizes in a way that we define and which we can use to train. It also allows us to have different dimensions for our edges and nodes as they are mapped onto a higher dimension anyway. For example, we are currently using [x, y , z, d] for the edge attribute (dimension = 4) whereas for the nodes we are using [node type, Input flow, Reynolds number], (dimension = 3). It maps the input data to a higher dimensional vector, with size 128 being used in the original deepmind paper. We have two separate encoders the edge and node encoders. The encoding process isn't explicitly determined, it is trained using an MLP with ReLu activation.\n",
        "\n",
        "Mathematically, the node encoding is simply:\n",
        "\n",
        "$$\n",
        "\\mathbf{z}_{i} = \\textrm{MLP} ( \\mathbf{h}_{i}) \\;      \\forall i \\in V\n",
        "$$\n",
        "\n",
        "the edge encoding is thus:\n",
        "\n",
        "$$\n",
        "\\mathbf{z}_{ij} = \\textrm{MLP} ( \\mathbf{h}_{ij}) \\;      \\forall edges \\in E\n",
        "$$\n",
        "\n",
        "# **Processor**\n",
        "\n",
        "The processor is the GNN message passing, aggregation, and update part of the architecture. It takes the graph with the new features generated by the encoder through the GNN pipeline: message, aggregation, and updates for the number of layers chosen.\n",
        "The processing layers of the MeshGraphNets is handled by a separate class, ProcessorLayer, which inherits from the PyG MessagePassing base class. The message is a learned transformation of MLP with skip connection on the self edge embedding concatenated with the embeddings of the conneccting nodes.\n",
        "\n",
        "The aggregation is done in two steps:\n",
        " 1) sum over the connected edges of each node\n",
        " 2) another MLP transformation of the edge sum concatenated with the self node.\n",
        "\n",
        "\n",
        " ### **Decoder**\n",
        "\n",
        "\n",
        "The decoder is a postprocessing step. It takes the node updates from the processor and maps it into a change in WSS using another separately learned MLP.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2oEoVihhVIJA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MeshGraphNet(torch.nn.Module):\n",
        "    def __init__(self, input_dim_node, input_dim_edge, hidden_dim, output_dim, args, emb=False):\n",
        "        super(MeshGraphNet, self).__init__()\n",
        "        \"\"\"\n",
        "        MeshGraphNet model. This model is built upon Deepmind's 2021 paper.\n",
        "        This model consists of three parts: (1) Preprocessing: encoder (2) Processor\n",
        "        (3) postproccessing: decoder. Encoder has an edge and node decoders respectively.\n",
        "        Processor has two processors for edge and node respectively. Note that edge attributes have to be\n",
        "        updated first. Decoder is only for nodes.\n",
        "\n",
        "        Input_dim: dynamic variables + node_type + node_position\n",
        "        Hidden_dim: 128 in deepmind's paper\n",
        "        Output_dim: dynamic variables: velocity changes (1)\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        self.num_layers = args.num_layers\n",
        "\n",
        "        # encoder convert raw inputs into higher dimensions.\n",
        "        self.node_encoder = Sequential(Linear(input_dim_node , hidden_dim),\n",
        "                              ReLU(),\n",
        "                              Linear( hidden_dim, hidden_dim),\n",
        "                              LayerNorm(hidden_dim))\n",
        "\n",
        "        self.edge_encoder = Sequential(Linear( input_dim_edge , hidden_dim),\n",
        "                              ReLU(),\n",
        "                              Linear( hidden_dim, hidden_dim),\n",
        "                              LayerNorm(hidden_dim)\n",
        "                              )\n",
        "\n",
        "\n",
        "        self.processor = nn.ModuleList()\n",
        "        assert (self.num_layers >= 1), 'Number of message passing layers is not >=1'\n",
        "\n",
        "        processor_layer=self.build_processor_model()\n",
        "        for _ in range(self.num_layers):\n",
        "            self.processor.append(processor_layer(hidden_dim,hidden_dim))\n",
        "\n",
        "\n",
        "        # decoder: only for node vectors\n",
        "        self.decoder = Sequential(Linear( hidden_dim , hidden_dim),\n",
        "                              ReLU(),\n",
        "                              Linear( hidden_dim, output_dim)\n",
        "                              )\n",
        "\n",
        "\n",
        "    def build_processor_model(self):\n",
        "        return ProcessorLayer\n",
        "\n",
        "\n",
        "    def forward(self,data,mean_vec_x,std_vec_x,mean_vec_edge,std_vec_edge):\n",
        "        \"\"\"\n",
        "        Encoder encodes graph (node/edge features) into latent vectors (node/edge embeddings)\n",
        "        The return of processor is fed into the processor for generating new feature vectors\n",
        "        \"\"\"\n",
        "        x, edge_index, edge_attr, wss = data.x, data.edge_index, data.edge_attr, data.y\n",
        "\n",
        "        x = normalize(x,mean_vec_x,std_vec_x)\n",
        "        edge_attr=normalize(edge_attr,mean_vec_edge,std_vec_edge)\n",
        "\n",
        "        # Step 1: encode node/edge features into latent node/edge embeddings\n",
        "        x = self.node_encoder(x) # output shape is the specified hidden dimension\n",
        "\n",
        "        edge_attr = self.edge_encoder(edge_attr) # output shape is the specified hidden dimension\n",
        "\n",
        "        # step 2: perform message passing with latent node/edge embeddings\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            # Calculate the update (delta)\n",
        "            x_res, edge_attr_res = self.processor[i](x, edge_index, edge_attr)\n",
        "\n",
        "            # Add update to the previous state\n",
        "            x = x + x_res\n",
        "            edge_attr = edge_attr + edge_attr_res\n",
        "\n",
        "\n",
        "        # step 3: decode latent node embeddings into physical quantities of interest\n",
        "\n",
        "        return self.decoder(x)\n",
        "\n",
        "    def loss(self, pred, inputs, mean_vec_y, std_vec_y):\n",
        "\n",
        "        # 1. Normalise the Ground Truth (y) to match the prediction scale\n",
        "        target = (inputs.y - mean_vec_y) / std_vec_y\n",
        "\n",
        "        # 2. Calculate Squared Error\n",
        "        error = (target - pred) ** 2\n",
        "\n",
        "        # 3. Root Mean Squared\n",
        "        loss = torch.sqrt(torch.mean(error))\n",
        "\n",
        "        return loss"
      ],
      "metadata": {
        "id": "RHqlXnYRfU3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Processor Layer**\n",
        "\n",
        "1.   **Message passing**\n",
        "\n",
        "Initiated by the propagate function, the message function most generally calculates messages, m, for edge u at layer l with function MSG given previous embeddings h_u:\n",
        "$$m_u^{(l)}=MSG^{(l)}(h_u^{(l-1)})$$\n",
        "\n",
        "Note that for MeshGraphNets, messages are calculated for edges and passed to nodes. This function thus takes edge embeddings and the adjacent node embeddings and concatenates them. These concatenated previous embeddings constitute h_u above. These are then put through an MLP (our MSG function) to give the final messages, m_u, which are passed to the aggregate function.\n",
        "\n",
        "2.   **Aggregation**\n",
        "\n",
        "Aggregation takes the updated edge embeddings and aggregates then over the connectivity matrix indexing using sum reduction. Most generally, we have:\n",
        "\n",
        "$$h_v^{(l)}=AGG^{(l)}(\\{m_u^{(l)},u\\in N(v)\\})$$\n",
        "\n",
        "For MeshGraphNets, aggregation (AGG) for node v is sum over the neighbor nodes. However, there is also an additional aggregation step: aggregating with the self embedding. This is done outside of the aggregation function, in the forward function after the return of propagate:\n",
        "\n",
        "$$h_v^{(l)}=\\{h_v^{(l-1)},AGG^{(l)}(\\{m_u^{(l)},u\\in N(v)\\})\\}$$\n",
        "\n",
        "3.   **Updating**\n",
        "\n",
        "The nodes embeddings are finally updated by passing $h_v^{(l)}$ through the node MLP with a skip connection. This is most generally written as:\n",
        "\n",
        "$$h_v^{(l)}=Processor(h_v^{(l)})$$\n",
        "\n",
        "Where for us the Processor is an MLP."
      ],
      "metadata": {
        "id": "2pGRuDbTf7xd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ProcessorLayer(MessagePassing):\n",
        "    def __init__(self, in_channels, out_channels,  **kwargs):\n",
        "        super(ProcessorLayer, self).__init__(  **kwargs )\n",
        "        \"\"\"\n",
        "        in_channels: dim of node embeddings [128], out_channels: dim of edge embeddings [128]\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        # Note that the node and edge encoders both have the same hidden dimension\n",
        "        # size. This means that the input of the edge processor will always be\n",
        "        # three times the specified hidden dimension\n",
        "        # (input: adjacent node embeddings and self embeddings)\n",
        "        self.edge_mlp = Sequential(Linear( 3* in_channels , out_channels),\n",
        "                                   ReLU(),\n",
        "                                   Linear( out_channels, out_channels),\n",
        "                                   LayerNorm(out_channels))\n",
        "\n",
        "        self.node_mlp = Sequential(Linear( 2* in_channels , out_channels),\n",
        "                                   ReLU(),\n",
        "                                   Linear( out_channels, out_channels),\n",
        "                                   LayerNorm(out_channels))\n",
        "\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        \"\"\"\n",
        "        reset parameters for stacked MLP layers\n",
        "        \"\"\"\n",
        "        self.edge_mlp[0].reset_parameters()\n",
        "        self.edge_mlp[2].reset_parameters()\n",
        "\n",
        "        self.node_mlp[0].reset_parameters()\n",
        "        self.node_mlp[2].reset_parameters()\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr, size = None):\n",
        "        \"\"\"\n",
        "        Handle the pre and post-processing of node features/embeddings,\n",
        "        as well as initiates message passing by calling the propagate function.\n",
        "\n",
        "        Note that message passing and aggregation are handled by the propagate\n",
        "        function, and the update\n",
        "\n",
        "        x has shpae [node_num , in_channels] (node embeddings)\n",
        "        edge_index: [2, edge_num]\n",
        "        edge_attr: [E, in_channels]\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        out, updated_edges = self.propagate(edge_index, x = x, edge_attr = edge_attr, size = size) # out has the shape of [E, out_channels]\n",
        "\n",
        "        updated_nodes = torch.cat([x,out],dim=1)        # Complete the aggregation through self-aggregation\n",
        "\n",
        "        updated_nodes = x + self.node_mlp(updated_nodes) # residual connection\n",
        "\n",
        "        return updated_nodes, updated_edges\n",
        "\n",
        "    def message(self, x_i, x_j, edge_attr):\n",
        "        \"\"\"\n",
        "        source_node: x_i has the shape of [E, in_channels]\n",
        "        target_node: x_j has the shape of [E, in_channels]\n",
        "        target_edge: edge_attr has the shape of [E, out_channels]\n",
        "\n",
        "        The messages that are passed are the raw embeddings. These are not processed.\n",
        "        \"\"\"\n",
        "\n",
        "        updated_edges=torch.cat([x_i, x_j, edge_attr], dim = 1) # tmp_emb has the shape of [E, 3 * in_channels]\n",
        "        updated_edges=self.edge_mlp(updated_edges)+edge_attr\n",
        "\n",
        "        return updated_edges\n",
        "\n",
        "    def aggregate(self, updated_edges, edge_index, dim_size = None):\n",
        "        \"\"\"\n",
        "        First we aggregate from neighbours (i.e., adjacent nodes) through concatenation,\n",
        "        then we aggregate self message (from the edge itself). This is streamlined\n",
        "        into one operation here.\n",
        "        \"\"\"\n",
        "\n",
        "        # The axis along which to index number of nodes.\n",
        "        node_dim = 0\n",
        "\n",
        "        out = torch_scatter.scatter(updated_edges, edge_index[0, :], dim=node_dim, reduce = 'sum')\n",
        "\n",
        "        return out, updated_edges"
      ],
      "metadata": {
        "id": "VhTb3XSUgfMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Building the optimiser**\n",
        "\n",
        "This defines a function which will allow us to play with the optimiser and learning rates. The Adam optimiser will be used by default as this was used in the original DeepMind paper.\n",
        "\n",
        "This can altered aftewards to see if the performance of the network can be improved."
      ],
      "metadata": {
        "id": "8VYinhN1whRP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_optimizer(args, params):\n",
        "    weight_decay = args.weight_decay\n",
        "    # Filter parameters that require gradients\n",
        "    filter_fn = filter(lambda p : p.requires_grad, params)\n",
        "\n",
        "    if args.opt == 'adam':\n",
        "        optimizer = optim.Adam(filter_fn, lr=args.lr, weight_decay=weight_decay)\n",
        "    elif args.opt == 'sgd':\n",
        "        optimizer = optim.SGD(filter_fn, lr=args.lr, momentum=0.95, weight_decay=weight_decay)\n",
        "    elif args.opt == 'rmsprop':\n",
        "        optimizer = optim.RMSprop(filter_fn, lr=args.lr, weight_decay=weight_decay)\n",
        "    elif args.opt == 'adagrad':\n",
        "        optimizer = optim.Adagrad(filter_fn, lr=args.lr, weight_decay=weight_decay)\n",
        "\n",
        "    if args.opt_scheduler == 'none':\n",
        "        return None, optimizer\n",
        "    elif args.opt_scheduler == 'step':\n",
        "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=args.opt_decay_step, gamma=args.opt_decay_rate)\n",
        "    elif args.opt_scheduler == 'cos':\n",
        "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.opt_restart)\n",
        "\n",
        "    return scheduler, optimizer"
      ],
      "metadata": {
        "id": "vlktVBuVwlRd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Main Training Loop**"
      ],
      "metadata": {
        "id": "7h_wZ-K9AI5i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataset, device, stats_list, args):\n",
        "    # --- Setup ---\n",
        "    # Convert stats to device\n",
        "    stats_list = [s.to(device) for s in stats_list]\n",
        "    [mean_vec_x, std_vec_x, mean_vec_edge, std_vec_edge, mean_vec_y, std_vec_y] = stats_list\n",
        "\n",
        "    # Create DataLoaders\n",
        "    # dataset[:n] slicing works if dataset is a list. If it's a PyG dataset object, use indexing carefully.\n",
        "    train_loader = DataLoader(dataset[:args.train_size], batch_size=args.batch_size, shuffle=True)\n",
        "    test_loader = DataLoader(dataset[args.train_size:], batch_size=args.batch_size, shuffle=False)\n",
        "\n",
        "    # Initialize Model\n",
        "    num_node_features = dataset[0].x.shape[1]\n",
        "    num_edge_features = dataset[0].edge_attr.shape[1]\n",
        "    num_classes = 1 # WSS is scalar\n",
        "\n",
        "    model = MeshGraphNet(num_node_features, num_edge_features, args.hidden_dim, num_classes, args).to(device)\n",
        "\n",
        "    # You need to define build_optimizer or use standard Adam\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
        "\n",
        "\n",
        "    # Logging\n",
        "    results_data = [] # Store dicts here, create DF at end\n",
        "    model_name = f'model_nl{args.num_layers}_hd{args.hidden_dim}_lr{args.lr}'\n",
        "\n",
        "    best_test_loss = np.inf\n",
        "    best_model = None\n",
        "\n",
        "    # --- Training Loop ---\n",
        "    for epoch in trange(args.epochs, desc=\"Training\", unit=\"Epochs\"):\n",
        "        total_loss = 0\n",
        "        model.train()\n",
        "        num_loops = 0\n",
        "\n",
        "        for batch in train_loader:\n",
        "            batch = batch.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward\n",
        "            pred = model(batch, mean_vec_x, std_vec_x, mean_vec_edge, std_vec_edge)\n",
        "\n",
        "            # Loss (Model handles normalization of target internally)\n",
        "            loss = model.loss(pred, batch, mean_vec_y, std_vec_y)\n",
        "\n",
        "            # Backward\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            num_loops += 1\n",
        "\n",
        "        avg_train_loss = total_loss / num_loops\n",
        "\n",
        "        # --- Evaluation (Every 10 epochs) ---\n",
        "        if epoch % 10 == 0:\n",
        "            # We always run validation to check progress\n",
        "            test_loss, wss_rmse = test(test_loader, device, model, stats_list, is_validation=True)\n",
        "\n",
        "            # Log results\n",
        "            results_data.append({\n",
        "                'epoch': epoch,\n",
        "                'train_loss': avg_train_loss,\n",
        "                'test_loss': test_loss,\n",
        "                'wss_rmse': wss_rmse\n",
        "            })\n",
        "\n",
        "            # Checkpoint Best Model\n",
        "            if test_loss < best_test_loss:\n",
        "                best_test_loss = test_loss\n",
        "                best_model = copy.deepcopy(model)\n",
        "                if args.save_best_model:\n",
        "                    torch.save(best_model.state_dict(), os.path.join(args.checkpoint_dir, model_name + '.pt'))\n",
        "\n",
        "            # Print Progress\n",
        "            print(f\" Ep {epoch}: Train Loss {avg_train_loss:.4f} | Test Loss {test_loss:.4f} | WSS RMSE {wss_rmse:.4f} Pa\")\n",
        "\n",
        "            # Save CSV log\n",
        "            if not os.path.isdir(args.checkpoint_dir): os.mkdir(args.checkpoint_dir)\n",
        "            pd.DataFrame(results_data).to_csv(os.path.join(args.checkpoint_dir, model_name + '.csv'), index=False)\n",
        "\n",
        "    return best_model, best_test_loss\n",
        "\n",
        "def test(loader, device, test_model, stats_list, is_validation=False):\n",
        "    '''\n",
        "    Calculates test set losses and validation set errors (RMSE in Pascals).\n",
        "    '''\n",
        "    # Unpack stats\n",
        "    [mean_vec_x, std_vec_x, mean_vec_edge, std_vec_edge, mean_vec_y, std_vec_y] = stats_list\n",
        "\n",
        "    loss_accum = 0\n",
        "    wss_rmse_accum = 0\n",
        "    num_loops = 0\n",
        "\n",
        "    test_model.eval() # Set model to evaluation mode\n",
        "\n",
        "    for data in loader:\n",
        "        data = data.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            # 1. Forward Pass\n",
        "            pred = test_model(data, mean_vec_x, std_vec_x, mean_vec_edge, std_vec_edge)\n",
        "\n",
        "            # 2. Calculate Loss (Normalized Space) - used for learning curves\n",
        "            # The model.loss function handles normalization of data.y internally\n",
        "            batch_loss = test_model.loss(pred, data, mean_vec_y, std_vec_y)\n",
        "            loss_accum += batch_loss.item()\n",
        "\n",
        "            # 3. Calculate Validation Error (Physical Space - Pascals)\n",
        "            if is_validation:\n",
        "                # A. Unnormalize the predictions back to Pascals\n",
        "                pred_physical = unnormalize(pred, mean_vec_y, std_vec_y)\n",
        "\n",
        "                # B. Get the ground truth (data.y is already physical/raw)\n",
        "                true_physical = data.y\n",
        "\n",
        "                # C. Calculate RMSE directly\n",
        "\n",
        "                error = (pred_physical - true_physical) ** 2\n",
        "                batch_rmse = torch.sqrt(torch.mean(error))\n",
        "\n",
        "                wss_rmse_accum += batch_rmse.item()\n",
        "\n",
        "        num_loops += 1\n",
        "\n",
        "    avg_test_loss = loss_accum / num_loops\n",
        "\n",
        "    if is_validation:\n",
        "        avg_wss_rmse = wss_rmse_accum / num_loops\n",
        "    else:\n",
        "        avg_wss_rmse = 0.0\n",
        "\n",
        "    return avg_test_loss, avg_wss_rmse"
      ],
      "metadata": {
        "id": "AuR42PwMwjO8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Specify parameters for model training*"
      ],
      "metadata": {
        "id": "_H7KCIFSAHC-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class objectview(object):\n",
        "    def __init__(self, d):\n",
        "        self.__dict__ = d\n",
        "\n",
        "for args in [\n",
        "        {'model_type': 'meshgraphnet',\n",
        "         'num_layers': 10,\n",
        "         'batch_size': 16,\n",
        "         'hidden_dim': 10,\n",
        "         'epochs': 500,\n",
        "         'opt': 'adam',\n",
        "         'opt_scheduler': 'none',\n",
        "         'opt_restart': 0,\n",
        "         'weight_decay': 5e-4,\n",
        "         'lr': 1e-4,\n",
        "         'train_size': 45,\n",
        "         'test_size': 10,\n",
        "         'device':'cuda',\n",
        "         'shuffle': True,\n",
        "         'save_wss_val': True,\n",
        "         'save_wss_model': True,\n",
        "         'checkpoint_dir': './checkpoints/',\n",
        "         'postprocess_dir': './plots/'},\n",
        "    ]:\n",
        "        args = objectview(args)\n",
        "\n",
        "#To ensure reproducibility the best we can, here we control the sources of\n",
        "#randomness by seeding the various random number generators used in this Colab\n",
        "\n",
        "torch.manual_seed(5)  #Torch\n",
        "random.seed(5)        #Python\n",
        "np.random.seed(5)     #NumPy"
      ],
      "metadata": {
        "id": "ghselvRI94fc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Load dataset*"
      ],
      "metadata": {
        "id": "8k15EGBDASpD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = GraphFolderDataset(output_dir)[:(args.train_size+args.test_size)]\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "khWbplbs-G_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Shuffle the dataset and get the statistics of the dataset*"
      ],
      "metadata": {
        "id": "X3vuluw-AZEo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stats_list = get_stats(dataset)\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "args.device = device\n",
        "print(device)"
      ],
      "metadata": {
        "id": "E0wyeQVvAAGZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training**"
      ],
      "metadata": {
        "id": "vzPUAkTMAfBS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_losses, losses, wss_val_losses, best_model, best_test_loss, test_loader = train(dataset, device, stats_list, args)\n",
        "\n",
        "print(\"Min test set loss: {0}\".format(min(test_losses)))\n",
        "print(\"Minimum loss: {0}\".format(min(losses)))\n",
        "if (args.save_wss_val):\n",
        "    print(\"Minimum wss validation loss: {0}\".format(min(wss_val_losses)))"
      ],
      "metadata": {
        "id": "tWdikTKRAjAK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}